{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets in svmlib format\n",
    "x, y = load_svmlight_file(\"dataset1.txt\")\n",
    "\n",
    "# X is scipy.sparse CSR matrix, we need to convert it to numpy array\n",
    "X = x.toarray()\n",
    "\n",
    "# scalling to [0,1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3) # 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: RBM Feautre Extraction + SVM\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True, n_components=128, learning_rate=0.01)\n",
    "svm = SVC(kernel=\"linear\")\n",
    "classifier = Pipeline(steps=[(\"rbm\", rbm),(\"svm\", svm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -201.17, time = 0.48s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -168.42, time = 0.53s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -150.00, time = 0.50s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -141.08, time = 0.50s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -136.14, time = 0.50s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -130.04, time = 0.50s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -125.52, time = 0.49s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -121.83, time = 0.50s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -118.16, time = 0.50s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -115.31, time = 0.51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.01, n_components=128, n_iter=10,\n",
       "       random_state=0, verbose=True)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict testing data\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.97      0.96       136\n",
      "        1.0       0.97      0.97      0.97       176\n",
      "        2.0       0.91      0.89      0.90       145\n",
      "        3.0       0.88      0.91      0.89       146\n",
      "        4.0       0.94      0.93      0.93       151\n",
      "        5.0       0.90      0.87      0.89       134\n",
      "        6.0       0.94      0.96      0.95       166\n",
      "        7.0       0.91      0.95      0.93       156\n",
      "        8.0       0.88      0.88      0.88       130\n",
      "        9.0       0.93      0.87      0.90       160\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1500\n",
      "\n",
      "[[132   0   0   0   0   0   3   0   1   0]\n",
      " [  0 171   1   1   1   0   0   1   1   0]\n",
      " [  1   1 129   4   2   0   5   1   2   0]\n",
      " [  0   0   1 133   0   4   0   2   5   1]\n",
      " [  0   0   1   1 140   1   2   0   2   4]\n",
      " [  1   1   3   6   0 117   0   1   3   2]\n",
      " [  0   0   2   1   0   2 160   0   1   0]\n",
      " [  1   1   1   0   1   0   0 148   0   4]\n",
      " [  2   1   3   4   0   5   0   0 115   0]\n",
      " [  1   1   0   2   5   1   0  10   1 139]]\n"
     ]
    }
   ],
   "source": [
    "# reporting classification results on testing data (performance)\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# reporting confusion matrix\n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
